Writing software for robots is difficult, particularly as the scale and scope
of robotics continues to grow. Different types of robots can have wildly varying
hardware, making code reuse non trivial. On top of this, the magnitude of
the required code can be daunting, as it must contain a deep stack starting
from driver-level software and continuing up through perception, abstract
reasoning, and beyond.

\section{Robot Operating System (ROS)}
Our choice fell on ROS (Robot Operating System) which is a widespread
open-source, meta-operating system for a robot. It provides several services
that are commonly offered by an operating system, including hardware
abstraction, low-level device control, implementation of commonly-used functionality,
message-passing between processes, and package management. It is
worth noting that the full source code of ROS is publicly available, ROS is
distributed under the terms of the BSD license, which allows the development
of both non-commercial and commercial projects.

\subsection{Nomencalture and Architecture}
In this section we simply outline the terminology adopted in the ROS
community to allow an easy comprehension of the following discussion.
\\
The fundamental concepts of the ROS implementation are \textit{nodes}, \textit{messages},
\textit{topics}, and \textit{services}.
In ROS a system is typically comprised of many nodes. In this context, the term
\textit{"node"} is interchangeable with \textit{"software module"}. The use of term 
\textit{"node"} arises from visualization of ROS-based systems at runtime:
when many nodes are running, it is convenient to render the peer-to-peer communications
as a graph, called the \textit{computation graph}, with process as graph nodes and 
the peer-to-peer links as arcs.
\\
Nodes communicate with each other by passing \textit{messages}. A message is a
a strictly typed data structure. Standard primitive types (integer, floating
point, boolean, etc.) are supported, as are arrays of primitive types and
constants. Messages can be composed of other messages, and arrays of other
messages, nested arbitrarily deep. Messages descriptions are usually stored
in \texttt{my\_package/msg/MyMessageType.msg} and define the data structures for
messages sent in ROS, called custom message.
\\ 
Here is a simple example of a \texttt{*.msg} file that uses a header, some integer primitive,
arrays of integer and array of other \texttt{*.msg} files. The message is specified 
in a language neutral interface definition language (IDL) which uses very short text 
files to describe its fields and allow an easy composition of complex messages:
\begin{multicols}{2}
\begin{lstlisting}
    Header      header
    bool        take
    bool        go_home
    uint32      ID_ROBOT
    uint32      item
    uint32      order
    uint32      demand
    uint32      dst
    uint32      path_distance
    uint32[]    route
\end{lstlisting}
The custom message above rappresent a \texttt{Task.msg} which contains the basic
information to define a task in the system. Instead, the custom message below, rappresent 
a \texttt{Mission.msg} which is composed of task messages addressed to a specific robot.  
\begin{lstlisting}
    Header      header
    uint32      ID_ROBOT
    uint32      capacity
    Task[]      Mission
\end{lstlisting}
\end{multicols}

These simple high-level message definitions is then parsed and processed by a code 
generator module, one for each support language (currentrly \texttt{C++}), which generates 
native implementations that “feel” like native objects, and are automatically 
serialized and deserialized by ROS as messages are sent and received.
\\
A node sends a message by publishing it to a given \textit{topic}, which is simply
a string such as \texttt{/topic} or \texttt{/pkg/topic}. A node that is interested
in a certain kind of data will subscribe to the appropriate topic. There may be multiple
concurrent publishers and subscribers for a single topic, and a single node
may publish and/or subscribe to multiple topics. In general, publishers and
subscribers are not aware of each other existence (decoupling). 
% Figure TODO: report an example \textit{computation graph}
It is important to point out that because nodes connect to each other at runtime,
the graph can be \textit{dynamically} modified.
\\
Although the topic-based publish-subscribe model is a flexible communications
paradigm, its “broadcast” routing scheme is not appropriate forsynchronous transactions,
which can simplify the design of some nodes.
For this purpose ROS includes the concept of \textit{services}, defined by a string name
and a pair of strictly typed messages: one for the request and one for the
response. A providing node offers a service under a name and a client uses
the service by sending the request message and awaiting the reply.
\\
As for the topic-based paradigm a high-level description of a service is then
parsed and processed by a code generator module which generates the corresponding
native implementation in a supported target language.
Usually C++ messages are generated in \texttt{my\_package/msg\_gen/cpp/include/my\_package},
while C++ services are generated in \texttt{my\_package/srv\_gen/cpp/include/my\_package}.
% TODO figura di differenze tra topic e service
To support collaborative development, the ROS software system is organized into \textit{packages}.
A ROS package is simply a directory which contains an XML file describing the package
and stating any dependencies. A collection of ROS packages is a directory tree with ROS
packages at the leaves: a ROS package repository may thus contain an arbitrarily complex
scheme of subdirectories. This structure is primarily meant to partition the building of 
ROS-based software into small, manageable chunks of functionality.
\\
In ROS, a \textit{stack} of software is a cluster of nodes that does something
coherent as a whole, as is illustrated in the simple \textit{navigation} example reported
in Figure. %TODO 
To allow for “packaged” functionality such as a navigation system, ROS provides
a tool called \texttt{roslaunch}, which reads an XML-like description of a graph and instantiates
the graph on the cluster, optionally on specific hosts.
Thus ROS is able to instantiate a set of nodes with a single
command, once the nodes are described in a \texttt{launch} file, the simple usage
is:
\begin{lstlisting}
    roslaunch [package] [filename.launch]
\end{lstlisting}

\subsection{The Stage 2D Simulation}
For visualization purposes we adopted the Stage 2D robot simulator
which provides a virtual world populated by mobile robots and enriched with
sensors, actuators and both approximate and exact localization. Stage is
designed to be sufficiently simple to allow an easy set-up but at the same time
it is intended to be just realistic enough to enable users to move controllers
directly between Stage robots and real robots. 
\\
Stage is made available in ROS with the \texttt{stageros} node which wraps the 
simulator and exposes its functionality to the rest of the system. The following 
code reports how it is launched:

\begin{lstlisting}
<?xml version="1.0" encoding="UTF-8" ?>
<launch>
    <arg name="map" default="grid" />
    <arg name="stage_pkg" default="stage_ros"/>     <!-- stage_pkg:=stage for ROS Groovy -->
    <arg name="custom_stage" default="false" />
    <group unless="$(arg custom_stage)"> 
        <node name="stageros" pkg="$(arg stage_pkg)" type="stageros" 
        args="$(find patrolling_sim)/maps/$(arg map)/$(arg map).world" output="screen" />
    </group>
    <group if="$(arg custom_stage)">   
        <node name="stageros" pkg="$(arg stage_pkg)" type="stageros" 
        args="$(find patrolling_sim)/maps/$(arg map)/$(arg map).world" output="screen">
            <param name="base_frame" value="base_link" />
            <param name="laser_topic" value="base_scan" />
            <param name="laser_frame" value="base_laser_link" />
        </node> 
    </group>
</launch>
\end{lstlisting}

The \texttt{*.world} file specified tells Stage everything about the world,
from obstacles (usually represented via a \texttt{*.pgm} image), to robots and other 
objects. In particular, after the definition of some parameters related to general 
camera and GUI options, we specify the static map on which the robot has to navigate 
(we will describe its characteristics shortly) and finally we include two specific 
files which aims defining the properties of respectively the laser sensor and the robot.
The last instruction just throws the robot in the map by indicating it's $x$, $y$, $z$
and $\theta$ coordinates, this is summarized in:
\begin{lstlisting}
include "../hokuyo.inc"
include "../crobot.inc"
include "../floorplan.inc"
include "../cpoint.inc"
window
( size   [ 460 180 1 ]         
  rotate [ 0.000 0.000 ]    
  center [ 11.5 4.0 ]   
  scale 20
  show_data 1)
floorplan
( size [23.0 8.0  1] 
  pose [11.5 4.0 0 0]
  bitmap "model5.pgm")
include "robots.inc"
include "point.inc"
\end{lstlisting}
The first included file (hokuyo.inc) defines the physical and technical
properties of the particular laser range finders support that we adopt: we
define it to have a circular shape and to be mounted on top of the robot base
which has the same circular shape. As for the sensor properties we specify
the following parameters described in:
\begin{lstlisting}
define hokuyo ranger
(
  sensor(           
    range [ 0.0  5.0 ] # the max/min range reported by the scanner, in meters.
    fov 230            # the angular field of view of the scanner, in degrees.
    samples 1081       # the number of laser samples per scan.
    )
  # model properties
  color "orange"
  size [ 0.1 0.1 0.1 ]
  block( points 4
    point[0] [0 0]
    point[1] [0 1]
    point[2] [1 1]
    point[3] [1 0]
    z [0 1])
)
\end{lstlisting}
The second included file (crobot.inc) defines the physical properties of
the robot, as mentioned above we define it to have a circular shape which
is suffice for our purpose of having a mobile camera that moves around the world:
\begin{lstlisting}
    define crobot position(
    size [0.3 0.3 0.2]
    origin [0 0 0 0]
    gui_nose 0
    drive "diff"

    # This block approximates a circular shape of a Robot
    block( points 16
        point[0] [ 0.225 0.000 ]
        point[1] [ 0.208 0.086 ]
        point[2] [ 0.159 0.159 ]
        point[3] [ 0.086 0.208 ]
        point[4] [ 0.000 0.225 ]
        point[5] [ -0.086 0.208 ]
        point[6] [ -0.159 0.159 ]
        point[7] [ -0.208 0.086 ]
        point[8] [ -0.225 0.000 ]
        point[9] [ -0.208 -0.086 ]
        point[10] [ -0.159 -0.159 ]
        point[11] [ -0.086 -0.208 ]
        point[12] [ -0.000 -0.225 ]
        point[13] [ 0.086 -0.208 ]
        point[14] [ 0.159 -0.159 ]
        point[15] [ 0.208 -0.086 ]
        z [0 1]
    )
    
    hokuyo( pose [0.15 0 -0.1 0] )

    # Report error-free position in world coordinates
    localization "gps"
    #localization_origin [ 0 0 0 0 ]

    # Some more realistic localization error
    localization "odom"
    odom_error [ 0.01 0.01 0.0 0.1 ]
)
\end{lstlisting}
% TODO sistemare gli spazzi bianchi

\section{Localization and Navigation}
Purpose of this section is to describing how we address the two main problems in
the context of mobile robotics: \textit{localization} and \textit{navigation}.
The former deals with tracking the pose of the robot during its motion allowing
it to localize itself in the map, the latter deals with driving the robot from a 
starting position to a goal position trying to avoid potential obstacles.
The complete code for the \texttt{launch} file in which this takes are solved is reported
below.
\begin{lstlisting}
    <?xml version="1.0" encoding="UTF-8" ?>
<launch>
  <arg name="robotname" default="robot_0" />
  <arg name="mapname" default="grid" />
  <arg name="use_amcl" default="true" />
  <arg name="use_move_base" default="true" />
  <arg name="use_srrg_localizer" default="false" />
  <arg name="use_spqrel_planner" default="false" />


  <group ns="$(arg robotname)">    
    
    <!-- Run the map server -->
    <node name="map_server" pkg="map_server" type="map_server" args="$(find patrolling_sim)/maps/$(arg mapname)/$(arg mapname).yaml" />

    <!-- Standard ROS navigation modules -->
    
    <group if="$(arg use_amcl)">
        <!--- AMCL -->
        <include file="$(find patrolling_sim)/params/amcl/amcl_diff.launch" />       
            
        <!-- Override AMCL Frame Params to include prefix -->
        <param name="/$(arg robotname)/amcl/base_frame_id" value="$(arg robotname)/base_link"/>
        <param name="/$(arg robotname)/amcl/odom_frame_id" value="$(arg robotname)/odom"/>
        <param name="/$(arg robotname)/amcl/global_frame_id" value="map"/> <!--common map frame for all robots -->
    </group>
        
    <group if="$(arg use_move_base)">
        <node pkg="move_base" type="move_base" respawn="false" name="move_base" output="screen">
            <rosparam file="$(find patrolling_sim)/params/move_base/costmap_common_params.yaml" command="load" ns="global_costmap" />
            <rosparam file="$(find patrolling_sim)/params/move_base/costmap_common_params.yaml" command="load" ns="local_costmap" />
            <rosparam file="$(find patrolling_sim)/params/move_base/local_costmap_params.yaml" command="load" />
            <rosparam file="$(find patrolling_sim)/params/move_base/global_costmap_params.yaml" command="load" />
            <rosparam file="$(find patrolling_sim)/params/move_base/base_local_planner_params.yaml" command="load" />
            <!-- remap from="cmd_vel" to="desired_cmd_vel" / -->
    
            <!-- Override MOVE_BASE Frame Params to include prefix -->
            <param name="global_costmap/laser_scan_sensor/sensor_frame" value="/$(arg robotname)/base_laser_link"/>
            <param name="global_costmap/laser_scan_sensor/topic" value="/$(arg robotname)/base_scan"/>
            <param name="global_costmap/robot_base_frame" value="/$(arg robotname)/base_link"/>   
            <param name="local_costmap/global_frame" value="/$(arg robotname)/odom"/>
            <param name="local_costmap/laser_scan_sensor/sensor_frame" value="/$(arg robotname)/base_laser_link"/>
            <param name="local_costmap/laser_scan_sensor/topic" value="/$(arg robotname)/base_scan"/>
            <param name="local_costmap/robot_base_frame" value="/$(arg robotname)/base_link"/> 
        </node>
    </group>


    <!-- spqrel_navigation modules from RoCoCo lab Sapienza University of Rome, Italy -->       

    <!--- srrg_localizer -->
    <group if="$(arg use_srrg_localizer)">
          <node pkg="tf" type="static_transform_publisher" name="link1_broadcaster" args="0 0 0 0 0 0 1 /map /$(arg robotname)/map 100" />
      
            
          <node pkg="spqrel_navigation" type="srrg_localizer2d_node" name="srrg_localizer" output="screen">
              <param name="global_frame_id" value="$(arg robotname)/map"/>
              <param name="base_frame_id" value="$(arg robotname)/base_link"/>
              <param name="odom_frame_id" value="$(arg robotname)/odom"/>
              <param name="laser_topic" value="$(arg robotname)/base_scan"/>
              <param name="use_gui" value="false"/>
          </node>
    </group>

    <!--- spqrel_planner -->    
    <group if="$(arg use_spqrel_planner)">            
           <node pkg="spqrel_navigation" type="spqrel_planner_node" name="spqrel_planner" output="screen">
              <param name="max_range" value="10.0"/>
              <param name="max_linear_vel" value="1.0"/>
              <param name="max_angular_vel" value="1.0"/>
              <param name="global_frame_id" value="$(arg robotname)/map"/>
              <param name="base_frame_id" value="$(arg robotname)/base_link"/>
              <param name="laser_topic" value="$(arg robotname)/base_scan"/>
              <param name="command_vel_topic" value="$(arg robotname)/cmd_vel"/>
              <param name="robot_radius" value="0.3"/> <!-- Raggio del robot -->
              <param name="use_gui" value="false"/>
           </node>
    </group>
    <!-- INITIAL POSES FOR LOCALIZER -->
    <include file="$(find patrolling_sim)/params/amcl/$(arg robotname)_initial_pose.xml" />
  </group>
</launch>
\end{lstlisting}

\subsection{Mapping}
The robot navigation system can be initialized with or without an a priori, \textit{static map}.
When initialized without a map, the robot only knows about obstacles that it has seen,
and will make optimistic global plans through areas that it has not yet visitied
which may traverse unknown space, potentially intersecting unseen obstacles. 
As the robot receives more information about the world, it replans accordingly to
avoid obstacles. Initialized with a static map, the robot will make informed plans 
about distant parts of the environment, using the map as prior obstacle information.
In our case we provide ROS with a static map of real laboratory in University of Verona.
Doing so requires us to set the \textit{map\_server} node that reads a map from 
disk and offers it via a ROS service:
\begin{lstlisting}
<!-- Run the map server -->
<node name="map_server" pkg="map_server" type="map_server" 
args="$(find patrolling_sim)/maps/$(arg mapname)/$(arg mapname).yaml" />
\end{lstlisting}
The current implementation of \textit{map\_server} convert color values in the map 
image data into ternary occupancy values: \textit{free}(0), \textit{occupied}(100), and
\textit{unknown}(-1).
\\
Maps manipulated by the tools in the \textit{map\_server} package are stored in a 
pair of file: the \texttt{*.yaml} file describes the map meta-data and names the image 
file while the image file encodes the occupancy data.
\\
The \texttt{*.yaml} file given as an argument to the \textit{map\_server} node is reported
below with a brief description of it's parameters.
\begin{lstlisting}
# path to the image file containing the occupancy data.
image: src/patrolling_sim/maps/model5/model5.pgm
# resolution of the map, meters/pixel.
resolution: 0.014100
# the 2-D pose of the lower-left pixel in the map, as (x, y, yaw).
origin: [0.000000, 0.000000, 0.000000]
# whether the white/black free/occupied semantics should be reversed.
negate: 0
# pixels with occupancy probability greater than this are considered completely occupied.
occupied_thresh: 0.65
# pixels with occupancy probability less than this are considered completely free.
free_thresh: 0.196
\end{lstlisting}

\subsection{Localization}
Both in the case of a given static map or without a given static map, we
require that the robot’s pose be tracked in a consistent global coordinate frame.
When not using a map, the robot’s pose is usually estimated by integrating
wheel odometry, possibly fused with data from an inertial measurement unit
(IMU). When using a map, as in our case, the robot is usually localized using
a probabilistic technique, in particular we adopt the Adaptive Monte Carlo
Localization (\texttt{amcl}) system:
\begin{lstlisting}
<group if="$(arg use_amcl)">
    <!--- AMCL -->
    <include file="$(find patrolling_sim)/params/amcl/amcl_diff.launch" />       
            
    <!-- Override AMCL Frame Params to include prefix -->
    <param name="/$(arg robotname)/amcl/base_frame_id" value="$(arg robotname)/base_link"/>
    <param name="/$(arg robotname)/amcl/odom_frame_id" value="$(arg robotname)/odom"/>
    
    <!--common map frame for all robots -->
    <param name="/$(arg robotname)/amcl/global_frame_id" value="map"/> 
</group>
\end{lstlisting}
\texttt{amcl} is a probabilistic localization system for a robot moving in 2D.
It implements the Adaptive (or KLD-sampling) Monte Carlo Localization
approach which uses a particle filter to track the pose of a robot against
a known map. The map of the environment where the robot has to localize
itself must be given to the robot beforehand. In our case the map is provided
by tha \textit{map\_server} node. This map is the so called \textit{occupacy map}
like before mentioned: it contains a value for every location which indicates the 
probability that this location is occupied by an object such as a wall. 
\texttt{amcl} takes in a laser-based map, laser scans and outputs pose estimates.
On startup, \texttt{amcl} initializes its particle filter according to the parameters
provided. In this respect we remark that the \texttt{amcl} node is launched only 
after having setting up three categories of ROS parameters that we use to configure 
its behaviour: \textit{overall filter}, \textit{laser model} and \textit{odometry model}.
The complete configuration file is reported below.
\begin{lstlisting}
<?xml version="1.0" encoding="UTF-8" ?>
<launch>
<arg name="robotname" default="robot_0" />
<node pkg="amcl" type="amcl" name="amcl" args="scan:=base_scan">
  <!-- Publish scans from best pose at a max of 10 Hz -->
  <param name="odom_model_type" value="diff"/>
  <param name="odom_alpha5" value="0.1"/>
  <param name="transform_tolerance" value="0.2" />
  <param name="gui_publish_rate" value="-10.0"/>
  <param name="laser_max_beams" value="30"/>
  <param name="min_particles" value="100"/>
  <param name="max_particles" value="500"/>
  <param name="kld_err" value="0.05"/>
  <param name="kld_z" value="0.99"/>
  <param name="odom_alpha1" value="0.2"/>
  <param name="odom_alpha2" value="0.2"/>
  <!-- translation std dev, m -->
  <param name="odom_alpha3" value="0.8"/>
  <param name="odom_alpha4" value="0.2"/>
  <param name="laser_z_hit" value="0.5"/>
  <param name="laser_z_short" value="0.05"/>
  <param name="laser_z_max" value="0.05"/>
  <param name="laser_z_rand" value="0.5"/>
  <param name="laser_sigma_hit" value="0.2"/>
  <param name="laser_lambda_short" value="0.1"/>
  <param name="laser_lambda_short" value="0.1"/>
  <param name="laser_model_type" value="likelihood_field"/>
  <!-- <param name="laser_model_type" value="beam"/> -->
  <param name="laser_likelihood_max_dist" value="2.0"/>
  <param name="update_min_d" value="0.2"/>
  <param name="update_min_a" value="0.5"/>
  <param name="odom_frame_id" value="odom"/>
  <param name="base_frame_id" value="base_link"/>
  <param name="resample_interval" value="1"/>
</node>
</launch>
\end{lstlisting}

\subsection{Navigation}
At high level the navigation system is quite simple. It takes in data from sensors,
odometry, and a navigation goal, and outputs velocity commands that are sent to a 
mobile base. The low-level architecture of system, however, is complex and consist 
of many components that interacts together.
\\
For navigation purposes we rely on the \textit{move\_base} package which provides 
an interface with the entire ROS navigation stack. The \textit{move\_base} package
provides an implementation of an \textit{action} that, given a goal in the world,
will attempt to reach it with a mobile base. It links together a \textit{global} and 
\textit{local} planner to accomplish its navigation task, it also maintains two 
costmaps, one for the global planner and one for the local planner.
An architecture view of the node its interaction with other components is show in 
Figure below. %TODO

The pre-requisites of navigation stack, along with a brief description of it's main 
components, are provided in the section below.
\subsection*{Trasformations}
Robotics systems often need to track spartial relationships between \textit{frames}
for a variety of reasons: between a mobile robot and some fixed frame of reference 
for localizzation or, as in our case, between the frame related to the mobile base 
and the one related to the laser sensor. To simplify the treatment of spartial frames,
a trasformation system has been written for ROS, called \texttt{tf}. The \texttt{tf} system 
constructs a dynamic \textit{trasformation tree} which realtes all frames of reference 
in the system. At an abstract level, a trasformation tree define \textit{offsets}
in terms of both translation and rotation between different coordinate frames.
\\
Referring to our case of a simple robot consisting of a circular mobile base
with a single laser support mounted on top of it we define two coordinate
frames: one corresponding to the center point of the base of the robot and one
for the center point of the laser support that is mounted on top of the base.
We've called the coordinate frame attached to the modile base \texttt{base\_link}
and the coordinate frame attached to the laser support \texttt{base\_laser\_link}.
Once this configuration in defined, every time that we have some data from the laser 
in the form of distances from the laser's center point and we want to take this data 
and use it to help the mobile base avoid obastacles in the world we invoke the \texttt{tf}
system which in the general case transforms the information towards the \texttt{base\_link}
coordiante frame. Below we reported the Figure which rappresent the configuration of 
\texttt{base\_link} and the \texttt{base\_laser\_link} frames.
%TODO figure of robot.
Our robot can thus use this information to reason about laser scans in
the \texttt{base\_link} frame and safely plan around obstacles in its environment.

\subsection*{Sensor Information}
The navigation stack uses information from sensors to avoid obstacles in the world,
it assumes that these sensors are publishing either \texttt{sensor\_msgs/LaserScan}
or \texttt{sensor\_msgs/PointCloud} message over ROS.
Publishing data correctly from sensors over ROS is important for the
navigation stack to operate safely. If the navigation stack receives no information
from a robot’s sensors, then of course it will drive blindly and, most
likely, hit things.
%TODO figure of one robot on map with laser 
Our \texttt{sensor\_msgs/LaserScan} message type, like many other messages sent 
over ROS, contain \texttt{tf} frame and time dependent information. To standardize 
how this information is sent, the \texttt{Header} message type is used as field
in all such messages.
The three field in the \texttt{Header} type are show below.
 %inserti image Header message laser scan
\begin{lstlisting}
# Standard metadata for higher-level flow data types
uint32 seq
time stamp
string frame_id
\end{lstlisting}
The \texttt{seq} field corresponds to an identifier that automatically increases
as messages are sent from a given publisher. The \texttt{stamp} field stores time 
information that should be associated with data in a message. The \texttt{frame\_id}
field stores \texttt{tf} frame information that should be associated with data 
in a message. 
The body of the \texttt{sensor\_msgs/LaserScan} message holds informations about 
any given scan and contains the associated geometric informations in the following
form:
\begin{lstlisting}
# Laser scans angles are measured counter clockwise, with 0 facing forward
Header header
float32 angle_min # start angle of the scan [rad]
float32 angle_max # end angle of the scan [rad]
float32 angle_increment # angular distance between measurements [rad]
float32 time_increment # time between measurements [seconds]
float32 scan_time # time between scans [seconds]
float32 range_min # minimum range value [m]
float32 range_max # maximum range value [m]
float32[] ranges # range data [m] (Note: values < range_min or > range_max
should be discarded)
float32[] intensities # intensity data [device-specific units]
\end{lstlisting}

\subsection*{Odometry Informations}
The navigation stack requires that odometry information be published using 
\texttt{tf} and the \texttt{nav\_msgs/Odometry} message. The last message in 
required because \texttt{tf} alone does not provide any information about the 
velocity of the robot, it is thus required that any \textit{odometry source} 
publishes both this kind of information to \textit{move\_base}.
\\
The \texttt{nav\_msgs/Odometry} message stores an estimate of the position and 
velocity of a robot in free space:
\begin{lstlisting}
# The pose in this message should be specified in the coordinate frame given
by header.frame_id.
# The twist in this message should be specified in the coordinate frame
given by the child_frame_id
Header header
string child_frame_id
geometry_msgs/PoseWithCovariance pose
geometry_msgs/TwistWithCovariance twist
\end{lstlisting}
The \textit{pose} in this message corresponds to the estimated position of the 
robot in the odometric frame of reference along with an optional covariance for 
the certainty of that pose estimate. The \textit{twist} in this message corresponds
to the robot's velocity in the child frame, normally the coordinate frame of the 
mobile base, along with an optional covariance for certainty of that velocity estimate.
\\
In our case since the \texttt{stageros} node represents the odometric source for 
the system,it is going to publish all the relevant trasformations between the
coordinate frames it manages towards the \texttt{/tf} topic which maintains the current 
trasformation tree for our system, and a \texttt{nav\_msgs/Odometry} message to 
the \texttt{/odom} topic so that the navigation stack can retrieve velocity information
from it.
%Image tf connection

\subsection*{Base Controller}
As previously specified the navigation stack assumes that it can send velocity commands
using a \texttt{geometry\_msgs/Twist} message assumed to be in the base coordinate
frame of the robot on the \texttt{/cmd\_vel} topic. This means there must be a node 
subscribing to the \texttt{/cmd\_vel} topic that is capable of talking 
$(v_x,v_y,v_\theta) \longleftrightarrow $ (\texttt{cmd\_vel.linear.x}, \texttt{cmd\_vel.linear.y}, \texttt{cmd\_vel.angular.z})
veloccities and converting them into motor commands to send a mobile base.
\\
In this work the \texttt{stageros} node subscribes to the \texttt{/cmd\_vel} topic
simulating the movement of a real robot in a real environment.

\subsection{Global and Local planner algorithms}

\subsection*{Global planner}
\subsection*{Local planner}
\section{Cost-maps configurations}
\section{Recovery behaviours}

